{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from  datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Prepare Datasets for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the correct data type for each column in the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *calendar.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Correct data types for \"calendar.csv\"\n",
    "calendarDTypes = {\"event_name_1\": \"category\", \n",
    "                  \"event_name_2\": \"category\", \n",
    "                  \"event_type_1\": \"category\", \n",
    "                  \"event_type_2\": \"category\", \n",
    "                  \"weekday\": \"category\", \n",
    "                  'wm_yr_wk': 'int16', \n",
    "                  \"wday\": \"int16\",\n",
    "                  \"month\": \"int16\", \n",
    "                  \"year\": \"int16\", \n",
    "                  \"snap_CA\": \"float32\", \n",
    "                  'snap_TX': 'float32', \n",
    "                  'snap_WI': 'float32' }\n",
    "\n",
    "# Read csv file\n",
    "calendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\", \n",
    "                       dtype = calendarDTypes)\n",
    "\n",
    "calendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col, colDType in calendarDTypes.items():\n",
    "    if colDType == \"category\":\n",
    "        calendar[col] = calendar[col].cat.codes.astype(\"int16\")\n",
    "        calendar[col] -= calendar[col].min()\n",
    "\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *sell_prices.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct data types for \"sell_prices.csv\"\n",
    "priceDTypes = {\"store_id\": \"category\", \n",
    "               \"item_id\": \"category\", \n",
    "               \"wm_yr_wk\": \"int16\",\n",
    "               \"sell_price\":\"float32\"}\n",
    "\n",
    "# Read csv file\n",
    "prices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\", \n",
    "                     dtype = priceDTypes)\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col, colDType in priceDTypes.items():\n",
    "    if colDType == \"category\":\n",
    "        prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "        prices[col] -= prices[col].min()\n",
    "        \n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *sales_train_validation.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstDay = 250\n",
    "lastDay = 1913\n",
    "\n",
    "# Use x sales days (columns) for training\n",
    "numCols = [f\"d_{day}\" for day in range(firstDay, lastDay+1)]\n",
    "\n",
    "# Define all categorical columns\n",
    "catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "\n",
    "# Define the correct data types for \"sales_train_validation.csv\"\n",
    "dtype = {numCol: \"float32\" for numCol in numCols} \n",
    "dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n",
    "\n",
    "# Read csv file\n",
    "ds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n",
    "                 usecols = catCols + numCols, dtype = dtype)\n",
    "\n",
    "# Transform categorical features into integers\n",
    "for col in catCols:\n",
    "    if col != \"id\":\n",
    "        ds[col] = ds[col].cat.codes.astype(\"int16\")\n",
    "        ds[col] -= ds[col].min()\n",
    "        \n",
    "ds = pd.melt(ds,\n",
    "             id_vars = catCols,\n",
    "             value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n",
    "             var_name = \"d\",\n",
    "             value_name = \"sales\")\n",
    "\n",
    "# Merge \"ds\" with \"calendar\" and \"prices\" dataframe\n",
    "ds = ds.merge(calendar, on = \"d\", copy = False)\n",
    "ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayLags = [7, 28]\n",
    "lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n",
    "for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "    ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n",
    "    \n",
    "windows = [7, 28]\n",
    "for window in windows:\n",
    "    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "        ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFeatures = {\"wday\": \"weekday\",\n",
    "                \"week\": \"weekofyear\",\n",
    "                \"month\": \"month\",\n",
    "                \"quarter\": \"quarter\",\n",
    "                \"year\": \"year\",\n",
    "                \"mday\": \"day\"}\n",
    "\n",
    "for featName, featFunc in dateFeatures.items():\n",
    "    if featName in ds.columns:\n",
    "        ds[featName] = ds[featName].astype(\"int16\")\n",
    "    else:\n",
    "        ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows with NaN value\n",
    "ds.dropna(inplace = True)\n",
    "\n",
    "# Define columns that need to be removed\n",
    "unusedCols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "trainCols = ds.columns[~ds.columns.isin(unusedCols)]\n",
    "X_train = ds[trainCols]\n",
    "y_train = ds[\"sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "\n",
    "# Define categorical features\n",
    "catFeats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n",
    "           [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "\n",
    "validInds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\n",
    "trainInds = np.setdiff1d(X_train.index.values, validInds)\n",
    "\n",
    "trainData = lgb.Dataset(X_train.loc[trainInds], label = y_train.loc[trainInds], \n",
    "                        categorical_feature = catFeats, free_raw_data = False)\n",
    "validData = lgb.Dataset(X_train.loc[validInds], label = y_train.loc[validInds],\n",
    "                        categorical_feature = catFeats, free_raw_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds, X_train, y_train, validInds, trainInds ; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          \"objective\" : \"poisson\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"force_row_wise\" : True,\n",
    "          \"learning_rate\" : 0.075,\n",
    "          \"sub_row\" : 0.75,\n",
    "          \"bagging_freq\" : 1,\n",
    "          \"lambda_l2\" : 0.1,\n",
    "          \"metric\": [\"rmse\"],\n",
    "          'verbosity': 1,\n",
    "          'num_iterations' : 1200,\n",
    "          'num_leaves': 128,\n",
    "          \"min_data_in_leaf\": 100,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM model\n",
    "m_lgb = lgb.train(params, trainData, valid_sets = [validData], verbose_eval = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "m_lgb.save_model(\"model.lgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last day used for training\n",
    "trLast = 1913\n",
    "# Maximum lag day\n",
    "maxLags = 57\n",
    "\n",
    "# Create dataset for predictions\n",
    "def create_ds():\n",
    "    \n",
    "    startDay = trLast - maxLags\n",
    "    \n",
    "    numCols = [f\"d_{day}\" for day in range(startDay, trLast + 1)]\n",
    "    catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    \n",
    "    dtype = {numCol:\"float32\" for numCol in numCols} \n",
    "    dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n",
    "    \n",
    "    ds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n",
    "                     usecols = catCols + numCols, dtype = dtype)\n",
    "    \n",
    "    for col in catCols:\n",
    "        if col != \"id\":\n",
    "            ds[col] = ds[col].cat.codes.astype(\"int16\")\n",
    "            ds[col] -= ds[col].min()\n",
    "    \n",
    "    for day in range(trLast + 1, trLast+ 28 +1):\n",
    "        ds[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    ds = pd.melt(ds,\n",
    "                 id_vars = catCols,\n",
    "                 value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n",
    "                 var_name = \"d\",\n",
    "                 value_name = \"sales\")\n",
    "    \n",
    "    ds = ds.merge(calendar, on = \"d\", copy = False)\n",
    "    ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def create_features(ds):          \n",
    "    dayLags = [7, 28]\n",
    "    lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n",
    "    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "        ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n",
    "\n",
    "    windows = [7, 28]\n",
    "    for window in windows:\n",
    "        for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n",
    "            ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())\n",
    "          \n",
    "    dateFeatures = {\"wday\": \"weekday\",\n",
    "                    \"week\": \"weekofyear\",\n",
    "                    \"month\": \"month\",\n",
    "                    \"quarter\": \"quarter\",\n",
    "                    \"year\": \"year\",\n",
    "                    \"mday\": \"day\"}\n",
    "\n",
    "    for featName, featFunc in dateFeatures.items():\n",
    "        if featName in ds.columns:\n",
    "            ds[featName] = ds[featName].astype(\"int16\")\n",
    "        else:\n",
    "            ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fday = datetime(2016,4, 25) \n",
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1/len(alphas)] * len(alphas)\n",
    "sub = 0.\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "    te = create_ds()\n",
    "    cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day)\n",
    "        tst = te[(te['date'] >= day - timedelta(days=maxLags)) & (te['date'] <= day)].copy()\n",
    "        create_features(tst)\n",
    "        tst = tst.loc[tst['date'] == day , trainCols]\n",
    "        te.loc[te['date'] == day, \"sales\"] = alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n",
    "\n",
    "    te_sub = te.loc[te['date'] >= fday, [\"id\", \"sales\"]].copy()\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace = True)\n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
